
Loom: https://www.loom.com/share/ddf55b4a022b4e1aa1007b74af17f389?sid=b2a10d06-c4a2-4083-8b94-eadeab1dcbd4
# Task 1: Defining your Problem and Audience

1. Write a succinct 1-sentence description of the problem
     - Many people nowadays do not have easy/free access to someone they can talk to about their problems.
2. Write 1-2 paragraphs on why this is a problem for your specific user

In today's fast-paced and increasingly digital world, many individuals find themselves isolated and lacking meaningful connections. The cost of professional therapy is often prohibitively expensive, with sessions ranging from $100 to $200 or more, making it inaccessible for a large portion of the population‚Äîespecially those without adequate insurance or financial resources. As a result, people who are struggling with emotional or mental health issues may have nowhere to turn for support, exacerbating their feelings of helplessness and distress.

This lack of accessible support is particularly concerning given the growing epidemic of loneliness. According to a 2023 report by the U.S. Surgeon General, nearly half of adults in the United States report experiencing loneliness, and this trend is mirrored globally. Social networks have shrunk, and people are more disconnected than ever before, leading to increased risks of depression, anxiety, and even physical health problems. For our specific users, those seeking someone to talk to but unable to afford therapy or find support in their immediate circles‚Äîthis problem is both urgent and deeply personal, highlighting the need for accessible, free, and empathetic avenues for conversation and connection.

# Task 2: Propose a Solution

1. Write 1-2 paragraphs on your proposed solution.  How will it look and feel to the user?
     The proposed solution is an AI agent that will continuously speak to the user inquiring them about any problems they have been facing and encourage them to take control and better their lives. The agent will remember context about the given user, and use that to enhance future suggestions for changes the user could make in their life. It will look like a regular chatting space for the user, but the idea is to cultivate a warmer/tough love type of agent that can give well-reasoned advice, but also be a great listener, prompting the user to go into the details of what is bothering them.
2. Describe the tools you plan to use in each part of your stack.  Write one sentence on why you made each tooling choice.
     1. LLM
          - OpenAI GPT-4: Chosen for its strong conversational abilities and nuanced understanding, making it perfect for empathetic, context-aware chat.
     2. Embedding Model
          - OpenAI text-embedding-3-small: Excels at capturing the semantic similarities between clinical therapeutic terminology and everyday emotional expressions, enabling the system to understand when users say "I can't get out of bed" and successfully retrieve relevant depression coping strategies from the therapy document.
     3. Orchestration
          LangGraph: Useful for creating conditional flows in case a user says that the advice given is not helpful.
     4. Vector Database
          - In-memory vector store: Stores and retrieves user context. Also great for local deployments.
     5. Monitoring
          - OpenAI API logging + backend logging: Keeps an eye on system health and usage.
     6. Evaluation
          - Manual review + LangChain/Ragas Evaluation: I will personally be checking the responses to see if they are empathetic and constructive. In addition, LangChain/Ragas will also be used to measure empathy, context recall, etc.
     7. User Interface
          - Next.js + React + Tailwind CSS: Delivers a modern chat experience.

3. Where will you use an agent or agents?  What will you use ‚Äúagentic reasoning‚Äù for in your app?
     The core of the app is a conversational AI agent that interacts directly with users, acting as both a supportive listener and a proactive coach. Agentic reasoning is used to remember the user‚Äôs context, ask thoughtful follow-up questions, and suggest personalized actions or advice based on previous conversations. The agent actively guides the conversation, nudges users toward self-reflection, and adapts its approach over time to better support each individual‚Äôs journey. This ‚Äútough love‚Äù agent leverages agentic reasoning to balance empathy with actionable suggestions, making every chat feel both caring and constructive.

# Task 3: Dealing with the Data

1. Describe all of your data sources and external APIs, and describe what you‚Äôll use them for.
      - Document generated by ChatGPT for the top 20 problems that humans face in their lifetime and how to go about dealing with them
      - Tavily API for when the user has a very niche specific problem that requires online research
      - User conversations will be stored in the vector store, to keep up with the user life context.

2. Describe the default chunking strategy that you will use.  Why did you make this decision?
     The default chunking strategy will be to split user conversations and any reference documents into manageable segments of around 500 tokens each, with a small overlap (for example, 50 tokens) between chunks. This approach ensures that each chunk contains enough context for meaningful semantic search and retrieval, while also preventing important information from being lost at chunk boundaries. The decision to use this strategy is based on balancing two needs: keeping chunks small enough for efficient vector search and LLM context windows, but large enough to preserve the flow and nuance of user conversations. Overlapping chunks help maintain continuity, so the agent can recall details even if they fall at the edge of a segment.
3. [Optional] Will you need specific data for any other part of your application? No.

# Task 4: Building a Quick End-to-End Agentic RAG Prototype
1. Build an end-to-end prototype and deploy it to a local endpoint
     Done.
# Task 5: Creating a Golden Test Data Set
1. Assess your pipeline using the RAGAS framework including key metrics faithfulness, response relevance, context precision, and context recall.  Provide a table of your output results.

## üéØ Agent Performance Evaluation (RAGAS Metrics)

| Metric | Score | Performance | Description |
|--------|-------|-------------|-------------|
| üéØ **Faithfulness** | 0.4208 | üî¥ Needs Work | How well responses stick to the source material (therapy doc) |
| üé™ **Answer Relevancy** | 0.6988 | üü° Decent | How well responses actually answer the user's question |
| üîç **Context Precision** | 0.0833 | üî¥ Critical Issue | How relevant the retrieved context is to the question |
| üìö **Context Recall** | 0.7466 | üü¢ Good | How well the system finds relevant info when it exists |

These results were outputted to the ragas_evaluation_results.json.

2. What conclusions can you draw about the performance and effectiveness of your pipeline with this information?
     Context Precision (0.0833) is severely low, meaning the RAG system retrieves mostly irrelevant information from the therapy document
     Faithfulness (0.4208) indicates significant hallucination, the agent frequently generates responses not grounded in the source material
     Answer Relevancy (0.6988) shows the agent generally understands what users are asking, but responses can miss the mark.
     Context Recall (0.7466) demonstrates the system can find relevant information when it exists.

# Task 6: The Benefits of Advanced Retrieval
1. Describe the retrieval techniques that you plan to try and to assess in your application.  Write one sentence on why you believe each technique will be useful for your use case.
     - Ensemble Retriever w/ BM25 retriever and vector search: This technique combines keyword-based BM25 search (to catch direct therapeutic terms like "depression," "anxiety," "grief") with semantic vector search (to understand varied user expressions), addressing the critical Context Precision issue where users describe problems differently than clinical terminology in the therapy document.
     - Contextual compression: This technique uses an LLM to extract only the most relevant portions of retrieved therapy content, providing users with focused, actionable therapeutic guidance instead of overwhelming them with full document sections, thereby improving response precision and user experience.
2. Test a host of advanced retrieval techniques on your application.
     - Testing has been done, results are in the JSON files in top-level directory:
          - ragas_evaluation_regular_RAG_results.json (Baseline)
          - ragas_evaluation_ensemble_agent.json (BM25 + Vector Search)
          - ragas_evaluation_contextual_compression.json (LLM Compression)

# Task 7: Assessing Performance

1. How does the performance compare to your original RAG application?  Test the fine-tuned embedding model using the RAGAS frameworks to quantify any improvements.  Provide results in a table.

## RAGAS Evaluation Results Comparison

| Retrieval Technique | Faithfulness | Answer Relevancy | Context Precision | Context Recall |
|---------------------|--------------|------------------|-------------------|----------------|
| **Original RAG** (Baseline) | 0.4208 | 0.6988 | 0.0833 | 0.7466 |
| **Ensemble Retriever** (BM25 + Vector) | 0.5833 | 0.8447 | 0.0833 | 0.7133 |
| **Contextual Compression** | 0.3363 | 0.6036 | 0.0833 | 0.6855 |

### Key Findings:
- **Best Overall Performance**: Ensemble Retriever shows significant improvements in Faithfulness (+38.6%) and Answer Relevancy (+20.9%)
- **Context Precision**: All techniques struggle equally with this metric (0.0833), indicating a consistent challenge in retrieving only relevant context
- **Context Recall**: Baseline performs best, with Ensemble close behind
- **Contextual Compression**: Shows decreased performance across most metrics, possibly due to over-compression losing important therapeutic context

2. Articulate the changes that you expect to make to your app in the second half of the course. How will you improve your application?
     - For an application like this, boosting the metrics in the evaluation is key. In addition, empathy needs to be measured in the responses. The agent should always be empathetic, yet constructive towards the user.
     - Adding user messages to context/vector store. Having a contextual backlog for a specific user should help shape responses to future questions the user may have.
     - My original idea is to actually have the agent speak directly to the user via a phone call. This would replace an impersonal alarm ringtone in the morning and allow the user to actually speak to the agent to gain clarity on their obstacles and how to overcome them before the day even starts.
     - The responses from the agent are also too verbose, no real user wants to read so much text. In a real-life therapist scenario, there is more of a conversational exchange than a long listening period.
     I expect to shorten the responses from the agent to ensure that the conversation feels more natural, almost like talking to a friend.